{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pURyDF4_i4sd",
        "outputId": "b82df53a-04b4-4a7c-efcc-c54ce2c91e3d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from kagglehub import dataset_download\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_oVkDxCjBcT",
        "outputId": "e496b343-348d-40a2-efeb-84b0cd33e146"
      },
      "outputs": [],
      "source": [
        "path = dataset_download(\"puneet6060/intel-image-classification\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "train_path = os.path.join(path, \"seg_train\", \"seg_train\")\n",
        "test_path = os.path.join(path, \"seg_test\", \"seg_test\")\n",
        "\n",
        "print(\"Classes in training folder:\", os.listdir(train_path))\n",
        "\n",
        "train_dataset = ImageFolder(root=train_path, transform=transform)\n",
        "test_dataset = ImageFolder(root=test_path, transform=transform)\n",
        "\n",
        "batch_size = 64\n",
        "num_workers = 6\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"âœ… Dataset loaded successfully!\")\n",
        "print(\"Classes:\", train_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-Tzrp8Pi_nl"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((150, 150)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvOs6NlPNQLj"
      },
      "source": [
        "The `transform` function is related to how to address image data. The following numbered bullets are about explanations;\n",
        "\n",
        "1. **`transforms.Resize((150, 150))`**: Resizes the input image to a fixed size of 150x150 pixels. This ensures all images have the same dimensions (although the original dataset gave its image size is 150x150), allowing the neural network model to train uniformly among various images.\n",
        "\n",
        "2. **`transforms.ToTensor()`**: Converts the image from a PIL image or NumPy array into a PyTorch tensor. It also scales the pixel values from the range [0, 255] to [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qisx7S6HjDmQ"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(residual)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6vBQ1YkjEs5"
      },
      "outputs": [],
      "source": [
        "class CustomSceneCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomSceneCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Original 8 layers\n",
        "        self.layer1 = ResidualBlock(16, 16)\n",
        "        self.layer2 = ResidualBlock(16, 32, stride=2)\n",
        "        self.layer3 = ResidualBlock(32, 32)\n",
        "        self.layer4 = ResidualBlock(32, 64, stride=2)\n",
        "        self.layer5 = ResidualBlock(64, 64)\n",
        "        self.layer6 = ResidualBlock(64, 128, stride=2)\n",
        "        self.layer7 = ResidualBlock(128, 128)\n",
        "        self.layer8 = ResidualBlock(128, 256, stride=2)\n",
        "        self.layer9 = ResidualBlock(256, 256)\n",
        "        self.layer10 = ResidualBlock(256, 512, stride=2)\n",
        "        self.layer11 = ResidualBlock(512, 512)\n",
        "        self.layer12 = ResidualBlock(512, 1024, stride=2)\n",
        "        self.layer13 = ResidualBlock(1024, 1024)\n",
        "        self.layer14 = ResidualBlock(1024, 2048, stride=2)\n",
        "        self.layer15 = ResidualBlock(2048, 2048)\n",
        "        self.layer16 = ResidualBlock(2048, 4096, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(4096, 1024)\n",
        "        self.fc_bn1 = nn.BatchNorm1d(1024)\n",
        "        self.fc2 = nn.Linear(1024, 256)\n",
        "        self.fc_bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        self.fc_bn3 = nn.BatchNorm1d(64)\n",
        "        self.fc4 = nn.Linear(64, 6)  # Output layer for 6 classes\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "        # Original 8 layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.layer7(x)\n",
        "        x = self.layer8(x)\n",
        "        \n",
        "        # Additional 8 layers\n",
        "        x = self.layer9(x)\n",
        "        x = self.layer10(x)\n",
        "        x = self.layer11(x)\n",
        "        x = self.layer12(x)\n",
        "        x = self.layer13(x)\n",
        "        x = self.layer14(x)\n",
        "        x = self.layer15(x)\n",
        "        x = self.layer16(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Updated FC layer forward pass\n",
        "        x = self.relu(self.fc_bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc_bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc_bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTYyeaNAjHk6"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "    return train_loss, train_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq8PeohiNM7L"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            test_loss += criterion(outputs, target).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "\n",
        "    return test_loss, test_accuracy, all_preds, all_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvMPVTfrjIrM",
        "outputId": "1f3b597c-ad6a-4b4b-8d5a-5cbf68fafdc4"
      },
      "outputs": [],
      "source": [
        "model_path = './intel_scene_cnn_model.pth'\n",
        "history_path = './intel_scene_cnn_history.pth'\n",
        "model = CustomSceneCNN().to(device)\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    train_time_compute = 0\n",
        "    print(f\"Loading pre-trained model from {model_path}\")\n",
        "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "    if os.path.exists(history_path):\n",
        "        history = torch.load(history_path)\n",
        "        train_losses = history['train_losses']\n",
        "        train_accuracies = history['train_accuracies']\n",
        "        test_losses = history['test_losses']\n",
        "        test_accuracies = history['test_accuracies']\n",
        "        print(f\"Loaded training history for {len(train_losses)} epochs\")\n",
        "    else:\n",
        "        print(\"No training history found. Evaluating current model performance...\")\n",
        "        test_loss, test_accuracy, _, _ = test(model, test_loader, criterion, device)\n",
        "        print(f'Loaded Model Test Accuracy: {test_accuracy:.2f}%')\n",
        "        train_losses = [0]\n",
        "        test_losses = [test_loss]\n",
        "        train_accuracies = [0]\n",
        "        test_accuracies = [test_accuracy]\n",
        "else:\n",
        "    print(\"No previously trained model found. Training from scratch...\")\n",
        "    train_time_compute = 0\n",
        "    start_time = time.time()\n",
        "    max_epochs = 20\n",
        "    patience = 3\n",
        "    best_accuracy = 0\n",
        "    no_improve_count = 0\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n",
        "        test_loss, test_accuracy, _, _ = test(model, test_loader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{max_epochs}, '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
        "              f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\"Model improved, saved to {model_path}\")\n",
        "            no_improve_count = 0\n",
        "        else:\n",
        "            no_improve_count += 1\n",
        "            print(f\"No improvement for {no_improve_count} epochs\")\n",
        "\n",
        "        history = {\n",
        "            'train_losses': train_losses,\n",
        "            'train_accuracies': train_accuracies,\n",
        "            'test_losses': test_losses,\n",
        "            'test_accuracies': test_accuracies\n",
        "        }\n",
        "        torch.save(history, history_path)\n",
        "\n",
        "        if no_improve_count >= patience:\n",
        "            print(f\"Early stopping after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f'Training completed in {training_time:.2f} seconds')\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "    print(f\"Loaded best model with accuracy: {best_accuracy:.2f}%\")\n",
        "    print(f\"Training history saved to {history_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
