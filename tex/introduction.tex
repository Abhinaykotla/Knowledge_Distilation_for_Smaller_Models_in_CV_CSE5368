\section{Introduction}

Deep neural networks have achieved remarkable success across a wide spectrum of computer vision problems,
ranging from simple image classification tasks, such as ImageNet \cite{deng2009imagenet},
to high-fidelity image generation using diffusion models \cite{ho2020denoising, rombach2022high, xia2023diffir} and \gls*{gan} models \cite{goodfellow2014generative, nazeri2019edgeconnect}.
Much of this progress, however, has been driven by increasingly larger model capacities:
billions of parameters, expansive training datasets, and considerable computational budgets â€”
even though such computationally expensive models deliver state-of-the-art performance.
Their intensive resource requirements pose serious obstacles to deploying them
on resource-constrained devices or in real-time and latency-sensitive back-end services,
such as smartphones or even low-end GPUs.
Closing the gap between accuracy and efficiency therefore remains one of the central research challenges in deep learning.

Image classification is a fundamental task in computer vision.
The goal is to predict the class of an image from a predefined set of categories.
Many other tasks, including object detection, image segmentation, and image generation,
are successfully built on top of image classification,
especially since AlexNet \cite{krizhevsky2012imagenet} revolutionized computer vision by outperforming traditional methods
with its deep learning-based approach.

In this project, the initial plan was to implement a knowledge distillation framework
for an image inpainting task using diffusion models,
aiming to restore masked regions of images.
Unfortunately, although training scripts for student models were successfully implemented and run with guidance from the teacher model DiffIR \cite{xia2023diffir},
both memory limitations and the computational burden
led to extremely long training times.
Training on the Places dataset \cite{zhou2017places} required more than 200 hours per epoch,
even when using 8-bit floating-point precision.
Given these constraints, we decided to pivot from image inpainting to image classification
in order to demonstrate the effectiveness of knowledge distillation
and to lay the groundwork for applying the technique to more complex tasks in the future.

Building on the code implemented in Assignment 2 of the CSE 5368 course,
we developed a knowledge distillation framework for the image classification task.
In the subsequent sections, we describe our knowledge distillation method,
present experimental results demonstrating its efficiency,
and discuss potential directions for future work.
