\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\bibliographystyle{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{hyperref}
\usepackage[acronym]{glossaries}

\makeglossaries

\newacronym{fid}{FID}{Fr√©chet Inception Distance}

\newcommand{\WP}[1]{\textcolor{red}{(Wonjun: #1)}}

\begin{document}

\title{TinyDiff: A Personalized Image Inpainting Models \\
{\footnotesize \WP{we might need a better title}}
}

\author{
\IEEEauthorblockN{Wonjun Park\textsuperscript{*}, Abhinay Kotla\textsuperscript{*}}
\thanks{* Equal Contribution. This paper is a part of the final project of the course for Spring 2025, CSE 5368: Neural Networks at the University of Texas at Arlington.}
\IEEEauthorblockA{\textit{Computer Science and Engineering} \\
\textit{University of Texas at Arlington} \\
Arlington, TX, USA \\
\{ wxp7177, axk5827 \}@mavs.uta.edu}
}

\maketitle

\begin{abstract}
    Diffusion Models have been successfully shown their capabilities to restore images from masked regions.
    Nevertheless, due to the scale of their sizes and parameters,
    leveraging those models in low computational devices like smartphones is still a challenge
    despite its advantages in terms of privacy and security.
    In this paper, TinyDiff, a quantized and distilled version of the diffusion model, is proposed to address this issue.
    The model is significantly small in terms of the number of parameters and the size, preserving the competitive performance.
    With this model, we expect that users with low computational devices are able to take advantages of both the diffusion model and the edge devices.
    The code is available at \href{https://github.com}{here}.
\end{abstract}

\begin{IEEEkeywords}
    image generation, diffusion models, knowledge distillation, teacher-student learning, quantization.
\end{IEEEkeywords}

\input{introduction}

\input{related-works}

\input{methodology}

\input{experiments}

\input{conclusion}

\bibliography{final-paper}

\printglossary[type=\acronymtype]

\end{document}
