\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\bibliographystyle{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage{hyperref}
\usepackage[acronym]{glossaries}

\makeglossaries

\newacronym{gan}{GAN}{Generative Adversarial Network}
\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{llm}{LLM}{Large Language Model}

\newcommand{\WP}[1]{\textcolor{red}{(Wonjun: #1)}}

\begin{document}

\title{
    Knowledge Distilation for Smaller Models\\in Computer Vision
}

\author{
\IEEEauthorblockN{\textbf{Wonjun Park\textsuperscript{*}, Abhinay Kotla\textsuperscript{*}}}\thanks{* Equal Contribution.}
\thanks{This paper is a part of the final project of the course for Spring 2025, CSE-5368-001: Neural Networks at the University of Texas at Arlington under Dr. Francklin Rivas.}
\IEEEauthorblockA{Computer Science and Engineering \\
University of Texas at Arlington \\
Arlington, TX, USA \\
\textit{ \{ wxp7177, axk5827 \}@mavs.uta.edu} }
}

\maketitle

\begin{abstract}
    % Diffusion Models have been successfully shown their capabilities to restore images from masked regions.
    % Nevertheless, due to the scale of their sizes and parameters,
    % leveraging those models in low computational devices like smartphones is still a challenge
    % despite its advantages in terms of privacy and security.
    % In this paper, TinyDiff, a quantized and distilled version of the diffusion model, is proposed to address this issue.
    % The model is significantly small in terms of the number of parameters and the size, preserving the competitive performance.
    % With this model, we expect that users with low computational devices are able to take advantages of both the diffusion model and the edge devices.
    % The code is available at \href{https://github.com}{here}.
    Knowledge distilation is a technique that allows deep learning models to transfer knowledge from a larger, more complex model (the teacher)
    to a smaller, more efficient model (the student).
    The technique can be adopted in various tasks including image classification and image generation.
    Among computer vision tasks, the paper specifically focuses on the image classification task to demonstrate the effectiveness of knowledge distillation, further highlighting the framework to apply the technique to other tasks.
    The results from the image classification task that is addressed in this paper
show that knowledge distillation is able to successfully decrease the size of the model while preserving the performance of the model.
    In particular, the distilled model achieves slightly better performance than the teacher model.
    We expect that the framework can be applied to other tasks in computer vision without affecting performance.
    The code is available at \href{https://github.com/Abhinaykotla/Knowledge_Distilation_for_Smaller_Models_in_CV_CSE5368}{here}.
\end{abstract}

\begin{IEEEkeywords}
    deep learning, computer vision, knowledge distillation, teacher-student learning, and quantization.
\end{IEEEkeywords}

\input{introduction}

\input{related-works}

\input{methodology}

\input{experiments}

\input{conclusion}

\bibliography{final-paper}

\printglossary[type=\acronymtype]

\end{document}
