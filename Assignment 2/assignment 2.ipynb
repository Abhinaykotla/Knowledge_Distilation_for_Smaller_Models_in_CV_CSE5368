{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "You will need to find a images set that you will use for classification using Convolutional Neural Networks. You will need to describe the process you followed for solving the problem. You will need to submit the Jupyter Notebook and the additional files may be needed for running the program.\n",
    "\n",
    "Please, only one submission per group.\n",
    "\n",
    "**Team**\\\n",
    "Abhinay Kotla (1002195827)\\\n",
    "Wonjun Park (1002237177)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel Image Classification\n",
    "\n",
    "https://www.kaggle.com/datasets/puneet6060/intel-image-classification\n",
    "\n",
    "The dataset consists of various scenes or objects like Natural Scenes. Specifically, the labels are\n",
    "\n",
    "* buildings\n",
    "* forest\n",
    "* glacier\n",
    "* mountain\n",
    "* sea\n",
    "* street\n",
    "\n",
    "The dataset enables a trained neural network model to classify those 6 labels.\n",
    "\n",
    "It was published for holding a competition on the [online platform](https://www.analyticsvidhya.com/datahack/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pURyDF4_i4sd",
    "outputId": "9a619a24-86e3-4e04-fd27-9d2045df2010"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from kagglehub import dataset_download\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6IlnLowi93Y",
    "outputId": "e34651b0-8c1e-4c38-c00f-54e327ddd6a8"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "    print(f\"GPU device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "    print(f\"GPU total memory available: {total_memory / 1024**2:.2f} MB\")\n",
    "\n",
    "    reserved_memory = torch.cuda.memory_reserved(0)\n",
    "    allocated_memory = torch.cuda.memory_allocated(0)\n",
    "    free_memory = total_memory - allocated_memory\n",
    "    print(f\"GPU free memory: {free_memory / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(\"CUDA is not available on this system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-Tzrp8Pi_nl"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),                \n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transform` function is related to how to address image data. The following numbered bullets are about explanations;\n",
    "\n",
    "1. **`transforms.Resize((150, 150))`**: Resizes the input image to a fixed size of 150x150 pixels. This ensures all images have the same dimensions (although the original dataset gave its image size is 150x150), allowing the neural network model to train uniformly among various images.\n",
    "\n",
    "2. **`transforms.ToTensor()`**: Converts the image from a PIL image or NumPy array into a PyTorch tensor. It also scales the pixel values from the range [0, 255] to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_oVkDxCjBcT",
    "outputId": "fc39b569-cd2b-4c75-bb52-f8785bd9daef"
   },
   "outputs": [],
   "source": [
    "path = dataset_download(\"puneet6060/intel-image-classification\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_path = os.path.join(path, \"seg_train\", \"seg_train\")\n",
    "test_path = os.path.join(path, \"seg_test\", \"seg_test\")\n",
    "\n",
    "print(\"Classes in training folder:\", os.listdir(train_path))\n",
    "\n",
    "train_dataset = ImageFolder(root=train_path, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_path, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 6\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"Classes:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "lmtXfUdbjCUo",
    "outputId": "340c0332-b16a-4869-dda5-9b6e754d6cc3"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset type:\", type(train_dataset))\n",
    "\n",
    "first_image, first_label = train_dataset[0]\n",
    "\n",
    "print(f\"Shape of the first image: {first_image.shape}\")  \n",
    "\n",
    "image_np = first_image.permute(1, 2, 0).numpy()\n",
    "image_np = (image_np * 0.5) + 0.5 \n",
    "\n",
    "plt.imshow(image_np)\n",
    "plt.title(f\"Label: {train_dataset.classes[first_label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qisx7S6HjDmQ"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6vBQ1YkjEs5"
   },
   "outputs": [],
   "source": [
    "class CustomSceneCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomSceneCNN, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "        self.layer1 = ResidualBlock(16, 16)              \n",
    "        self.layer2 = ResidualBlock(16, 32, stride=2)   \n",
    "        self.layer3 = ResidualBlock(32, 32)              \n",
    "        self.layer4 = ResidualBlock(32, 64, stride=2)    \n",
    "        self.layer5 = ResidualBlock(64, 64)             \n",
    "\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 6)  \n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.relu(self.fc_bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc_bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9b_hvcwjFoi",
    "outputId": "be5b3892-65c4-40b6-9130-285d1db3f51e"
   },
   "outputs": [],
   "source": [
    "model = CustomSceneCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "conv_layers = sum(1 for module in model.modules() if isinstance(module, nn.Conv2d))\n",
    "print(f\"Number of layers: {conv_layers}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTYyeaNAjHk6"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100. * correct / total\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aq8PeohiNM7L"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, target).item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100. * correct / total\n",
    "\n",
    "    return test_loss, test_accuracy, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvMPVTfrjIrM",
    "outputId": "168fd98d-5629-4b7d-b026-b65745e0b6ed"
   },
   "outputs": [],
   "source": [
    "model_path = './intel_scene_cnn_model.pth'\n",
    "history_path = './intel_scene_cnn_history.pth'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    train_time_compute = 0\n",
    "    print(f\"Loading pre-trained model from {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        history = torch.load(history_path)\n",
    "        train_losses = history['train_losses']\n",
    "        train_accuracies = history['train_accuracies']\n",
    "        test_losses = history['test_losses']\n",
    "        test_accuracies = history['test_accuracies']\n",
    "        print(f\"Loaded training history for {len(train_losses)} epochs\")\n",
    "    else:\n",
    "        print(\"No training history found. Evaluating current model performance...\")\n",
    "        test_loss, test_accuracy, _, _ = test(model, test_loader, criterion, device)\n",
    "        print(f'Loaded Model Test Accuracy: {test_accuracy:.2f}%')\n",
    "        train_losses = [0]\n",
    "        test_losses = [test_loss]\n",
    "        train_accuracies = [0]\n",
    "        test_accuracies = [test_accuracy]\n",
    "else:\n",
    "    print(\"No previously trained model found. Training from scratch...\")\n",
    "    train_time_compute = 0\n",
    "    start_time = time.time()\n",
    "    max_epochs = 20\n",
    "    patience = 3\n",
    "    best_accuracy = 0\n",
    "    no_improve_count = 0\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n",
    "        test_loss, test_accuracy, _, _ = test(model, test_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{max_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%')\n",
    "\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model improved, saved to {model_path}\")\n",
    "            no_improve_count = 0\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(f\"No improvement for {no_improve_count} epochs\")\n",
    "\n",
    "        history = {\n",
    "            'train_losses': train_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'test_losses': test_losses,\n",
    "            'test_accuracies': test_accuracies\n",
    "        }\n",
    "        torch.save(history, history_path)\n",
    "\n",
    "        if no_improve_count >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f'Training completed in {training_time:.2f} seconds')\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    print(f\"Loaded best model with accuracy: {best_accuracy:.2f}%\")\n",
    "    print(f\"Training history saved to {history_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UOBNlkqjJyw",
    "outputId": "81aa0132-f09d-4598-b187-4c80e83c9f87"
   },
   "outputs": [],
   "source": [
    "if train_time_compute:\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f'Training completed in {training_time:.2f} seconds')\n",
    "\n",
    "_, final_accuracy, all_preds, all_targets = test(model, test_loader, criterion, device)\n",
    "print(f'Final Test Accuracy: {final_accuracy:.2f}%')\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=train_dataset.classes,\n",
    "            yticklabels=train_dataset.classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
